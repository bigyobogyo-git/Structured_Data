{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8560ba01-067c-468e-8bd4-fe9b8cc8ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 20:17:15.643407: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762456635.655662   23707 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762456635.659268   23707 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762456635.669768   23707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762456635.669783   23707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762456635.669785   23707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762456635.669786   23707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-06 20:17:15.673303: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # or jax, or tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124f0927-883d-46ab-8da3-f916860001da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/static/public/117/census+income+kdd.zip\n",
      "9428992/Unknown \u001b[1m2s\u001b[0m 0us/step"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/xy/.keras/datasets/census+income+kdd.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column names.\n",
    "CSV_HEADER = [\n",
    "    \"age\",\n",
    "    \"class_of_worker\",\n",
    "    \"detailed_industry_recode\",\n",
    "    \"detailed_occupation_recode\",\n",
    "    \"education\",\n",
    "    \"wage_per_hour\",\n",
    "    \"enroll_in_edu_inst_last_wk\",\n",
    "    \"marital_stat\",\n",
    "    \"major_industry_code\",\n",
    "    \"major_occupation_code\",\n",
    "    \"race\",\n",
    "    \"hispanic_origin\",\n",
    "    \"sex\",\n",
    "    \"member_of_a_labor_union\",\n",
    "    \"reason_for_unemployment\",\n",
    "    \"full_or_part_time_employment_stat\",\n",
    "    \"capital_gains\",\n",
    "    \"capital_losses\",\n",
    "    \"dividends_from_stocks\",\n",
    "    \"tax_filer_stat\",\n",
    "    \"region_of_previous_residence\",\n",
    "    \"state_of_previous_residence\",\n",
    "    \"detailed_household_and_family_stat\",\n",
    "    \"detailed_household_summary_in_household\",\n",
    "    \"instance_weight\",\n",
    "    \"migration_code-change_in_msa\",\n",
    "    \"migration_code-change_in_reg\",\n",
    "    \"migration_code-move_within_reg\",\n",
    "    \"live_in_this_house_1_year_ago\",\n",
    "    \"migration_prev_res_in_sunbelt\",\n",
    "    \"num_persons_worked_for_employer\",\n",
    "    \"family_members_under_18\",\n",
    "    \"country_of_birth_father\",\n",
    "    \"country_of_birth_mother\",\n",
    "    \"country_of_birth_self\",\n",
    "    \"citizenship\",\n",
    "    \"own_business_or_self_employed\",\n",
    "    \"fill_inc_questionnaire_for_veterans_admin\",\n",
    "    \"veterans_benefits\",\n",
    "    \"weeks_worked_in_year\",\n",
    "    \"year\",\n",
    "    \"income_level\",\n",
    "]\n",
    "\n",
    "data_url = \"https://archive.ics.uci.edu/static/public/117/census+income+kdd.zip\"\n",
    "keras.utils.get_file(origin=data_url, extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a97cdf6c-1e4b-4dd7-acbf-48ade81be225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (199523, 42)\n",
      "Test data shape: (99762, 42)\n"
     ]
    }
   ],
   "source": [
    "extracted_path = os.path.join(\n",
    "    os.path.expanduser(\"~\"), \".keras\", \"datasets\", \"census+income+kdd.zip\"\n",
    ")\n",
    "for root, dirs, files in os.walk(extracted_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".tar.gz\"):\n",
    "            tar_gz_path = os.path.join(root, file)\n",
    "            with tarfile.open(tar_gz_path, \"r:gz\") as tar:\n",
    "                tar.extractall(path=root)\n",
    "\n",
    "train_data_path = os.path.join(\n",
    "    os.path.expanduser(\"~\"),\n",
    "    \".keras\",\n",
    "    \"datasets\",\n",
    "    \"census+income+kdd.zip\",\n",
    "    \"census-income.data\",\n",
    ")\n",
    "test_data_path = os.path.join(\n",
    "    os.path.expanduser(\"~\"),\n",
    "    \".keras\",\n",
    "    \"datasets\",\n",
    "    \"census+income+kdd.zip\",\n",
    "    \"census-income.test\",\n",
    ")\n",
    "\n",
    "data = pd.read_csv(train_data_path, header=None, names=CSV_HEADER)\n",
    "test_data = pd.read_csv(test_data_path, header=None, names=CSV_HEADER)\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50259132-a5b2-4725-a9f9-4b500e7e589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"income_level\"] = data[\"income_level\"].apply(\n",
    "    lambda x: 0 if x == \" - 50000.\" else 1\n",
    ")\n",
    "test_data[\"income_level\"] = test_data[\"income_level\"].apply(\n",
    "    lambda x: 0 if x == \" - 50000.\" else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b20c41b-fea7-4970-897f-81fbc0731351",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_selection = np.random.rand(len(data.index)) <= 0.85\n",
    "train_data = data[random_selection]\n",
    "valid_data = data[~random_selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4111ceed-f2b3-48e9-a1bb-9b8a6a577703",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "valid_data_file = \"valid_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False, header=False)\n",
    "valid_data.to_csv(valid_data_file, index=False, header=False)\n",
    "test_data.to_csv(test_data_file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1afa7d56-f850-4ea6-a17e-adcf84d57312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target feature name.\n",
    "TARGET_FEATURE_NAME = \"income_level\"\n",
    "# Weight column name.\n",
    "WEIGHT_COLUMN_NAME = \"instance_weight\"\n",
    "# Numeric feature names.\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"age\",\n",
    "    \"wage_per_hour\",\n",
    "    \"capital_gains\",\n",
    "    \"capital_losses\",\n",
    "    \"dividends_from_stocks\",\n",
    "    \"num_persons_worked_for_employer\",\n",
    "    \"weeks_worked_in_year\",\n",
    "]\n",
    "# Categorical features and their vocabulary lists.\n",
    "# Note that we add 'v=' as a prefix to all categorical feature values to make\n",
    "# sure that they are treated as strings.\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    feature_name: sorted([str(value) for value in list(data[feature_name].unique())])\n",
    "    for feature_name in CSV_HEADER\n",
    "    if feature_name\n",
    "    not in list(NUMERIC_FEATURE_NAMES + [WEIGHT_COLUMN_NAME, TARGET_FEATURE_NAME])\n",
    "}\n",
    "# All features names.\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + list(\n",
    "    CATEGORICAL_FEATURES_WITH_VOCABULARY.keys()\n",
    ")\n",
    "# Feature default values.\n",
    "COLUMN_DEFAULTS = [\n",
    "    (\n",
    "        [0.0]\n",
    "        if feature_name\n",
    "        in NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME, WEIGHT_COLUMN_NAME]\n",
    "        else [\"NA\"]\n",
    "    )\n",
    "    for feature_name in CSV_HEADER\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1158a340-eb6e-44bc-9cf0-b4e69cd84c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow required for tf.data.Datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# We process our datasets elements here (categorical) and convert them to indices to avoid this step\n",
    "# during model training since only tensorflow support strings.\n",
    "def process(features, target):\n",
    "    for feature_name in features:\n",
    "        if feature_name in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n",
    "            # Cast categorical feature values to string.\n",
    "            features[feature_name] = tf.cast(features[feature_name], \"string\")\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "            # Create a lookup to convert a string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            index = layers.StringLookup(\n",
    "                vocabulary=vocabulary,\n",
    "                mask_token=None,\n",
    "                num_oov_indices=0,\n",
    "                output_mode=\"int\",\n",
    "            )\n",
    "            # Convert the string input values into integer indices.\n",
    "            value_index = index(features[feature_name])\n",
    "            features[feature_name] = value_index\n",
    "        else:\n",
    "            # Do nothing for numerical features\n",
    "            pass\n",
    "\n",
    "    # Get the instance weight.\n",
    "    weight = features.pop(WEIGHT_COLUMN_NAME)\n",
    "    # Change features from OrderedDict to Dict to match Inputs as they are Dict.\n",
    "    return dict(features), target, weight\n",
    "\n",
    "\n",
    "def get_dataset_from_csv(csv_file_path, shuffle=False, batch_size=128):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=False,\n",
    "        shuffle=shuffle,\n",
    "    ).map(process)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14f744a-0094-4415-98df-be0a1e55e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n",
    "            # Make them int64, they are Categorical (whole units)\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=\"int64\"\n",
    "            )\n",
    "        else:\n",
    "            # Make them float32, they are Real numbers\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=\"float32\"\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b50830d-d06b-4281-8300-c973f584441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedLinearUnit(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.linear = layers.Dense(units)\n",
    "        self.sigmoid = layers.Dense(units, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.linear(inputs) * self.sigmoid(inputs)\n",
    "\n",
    "    # Remove build warnings\n",
    "    def build(self):\n",
    "        self.built = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7412cf16-5eb3-4dd3-ac29-f78623a0dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedResidualNetwork(layers.Layer):\n",
    "    def __init__(self, units, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.elu_dense = layers.Dense(units, activation=\"elu\")\n",
    "        self.linear_dense = layers.Dense(units)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.gated_linear_unit = GatedLinearUnit(units)\n",
    "        self.layer_norm = layers.LayerNormalization()\n",
    "        self.project = layers.Dense(units)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.elu_dense(inputs)\n",
    "        x = self.linear_dense(x)\n",
    "        x = self.dropout(x)\n",
    "        if inputs.shape[-1] != self.units:\n",
    "            inputs = self.project(inputs)\n",
    "        x = inputs + self.gated_linear_unit(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "    # Remove build warnings\n",
    "    def build(self):\n",
    "        self.built = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b704237-913a-485a-89a7-1c4f7da56b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableSelection(layers.Layer):\n",
    "    def __init__(self, num_features, units, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        # Create an embedding layers with the specified dimensions\n",
    "        self.embeddings = dict()\n",
    "        for input_ in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[input_]\n",
    "            embedding_encoder = layers.Embedding(\n",
    "                input_dim=len(vocabulary), output_dim=self.units, name=input_\n",
    "            )\n",
    "            self.embeddings[input_] = embedding_encoder\n",
    "\n",
    "        # Projection layers for numeric features\n",
    "        self.proj_layer = dict()\n",
    "        for input_ in NUMERIC_FEATURE_NAMES:\n",
    "            proj_layer = layers.Dense(units=self.units)\n",
    "            self.proj_layer[input_] = proj_layer\n",
    "\n",
    "        self.grns = list()\n",
    "        # Create a GRN for each feature independently\n",
    "        for idx in range(num_features):\n",
    "            grn = GatedResidualNetwork(units, dropout_rate)\n",
    "            self.grns.append(grn)\n",
    "        # Create a GRN for the concatenation of all the features\n",
    "        self.grn_concat = GatedResidualNetwork(units, dropout_rate)\n",
    "        self.softmax = layers.Dense(units=num_features, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        concat_inputs = []\n",
    "        for input_ in inputs:\n",
    "            if input_ in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n",
    "                max_index = self.embeddings[input_].input_dim - 1  # Clamp the indices\n",
    "                # torch had some index errors during embedding hence the clip function\n",
    "                embedded_feature = self.embeddings[input_](\n",
    "                    keras.ops.clip(inputs[input_], 0, max_index)\n",
    "                )\n",
    "                concat_inputs.append(embedded_feature)\n",
    "            else:\n",
    "                # Project the numeric feature to encoding_size using linear transformation.\n",
    "                proj_feature = keras.ops.expand_dims(inputs[input_], -1)\n",
    "                proj_feature = self.proj_layer[input_](proj_feature)\n",
    "                concat_inputs.append(proj_feature)\n",
    "\n",
    "        v = layers.concatenate(concat_inputs)\n",
    "        v = self.grn_concat(v)\n",
    "        v = keras.ops.expand_dims(self.softmax(v), axis=-1)\n",
    "        x = []\n",
    "        for idx, input in enumerate(concat_inputs):\n",
    "            x.append(self.grns[idx](input))\n",
    "        x = keras.ops.stack(x, axis=1)\n",
    "        return keras.ops.squeeze(\n",
    "            keras.ops.matmul(keras.ops.transpose(v, axes=[0, 2, 1]), x), axis=1\n",
    "        )\n",
    "\n",
    "    # to remove the build warnings\n",
    "    def build(self):\n",
    "        self.built = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cec7e6ca-6b75-47e0-8fbd-9d3549194024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(encoding_size):\n",
    "    inputs = create_model_inputs()\n",
    "    num_features = len(inputs)\n",
    "    features = VariableSelection(num_features, encoding_size, dropout_rate)(inputs)\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(features)\n",
    "    # Functional model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e8f603-d2ea-4854-9618-26149e512be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762456690.161400   23707 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8902 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "dropout_rate = 0.15\n",
    "batch_size = 265\n",
    "num_epochs = 20  # may be adjusted to a desired value\n",
    "encoding_size = 16\n",
    "\n",
    "model = create_model(encoding_size)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "046d2fe4-76ef-4aca-97bb-44be99094029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762456723.353658   23858 service.cc:152] XLA service 0x7038f4037930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762456723.353677   23858 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2025-11-06 20:18:44.283457: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1762456729.046044   23858 cuda_dnn.cc:529] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown \u001b[1m54s\u001b[0m 17ms/step - accuracy: 0.7064 - loss: 782.1512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762456751.587732   23858 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    640/Unknown \u001b[1m89s\u001b[0m 54ms/step - accuracy: 0.9366 - loss: 287.5477"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 20:19:46.311374: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-11-06 20:19:46.311747: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_16]]\n",
      "/home/xy/Desktop/ml/tf_2.20/tf_2.20/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 67ms/step - accuracy: 0.9455 - loss: 251.5938 - val_accuracy: 0.9484 - val_loss: 228.7542\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 20:19:54.512519: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_8]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9494 - loss: 230.8637 - val_accuracy: 0.9499 - val_loss: 221.8072\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 20:20:04.215920: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_8]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9499 - loss: 227.1892 - val_accuracy: 0.9493 - val_loss: 219.7274\n",
      "Epoch 4/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9506 - loss: 225.0679 - val_accuracy: 0.9499 - val_loss: 217.2007\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 20:20:24.135184: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_8]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9505 - loss: 223.6594 - val_accuracy: 0.9511 - val_loss: 218.2379\n",
      "Epoch 6/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9511 - loss: 222.1899 - val_accuracy: 0.9513 - val_loss: 214.4742\n",
      "Epoch 7/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9511 - loss: 221.2353 - val_accuracy: 0.9495 - val_loss: 217.1089\n",
      "Epoch 8/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9513 - loss: 220.1887 - val_accuracy: 0.9518 - val_loss: 214.8790\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 20:21:00.993104: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_8]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9515 - loss: 219.1276 - val_accuracy: 0.9512 - val_loss: 213.3645\n",
      "Epoch 10/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9517 - loss: 218.3504 - val_accuracy: 0.9508 - val_loss: 213.2932\n",
      "Epoch 11/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9514 - loss: 217.8767 - val_accuracy: 0.9516 - val_loss: 211.8683\n",
      "Epoch 12/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9520 - loss: 216.9544 - val_accuracy: 0.9517 - val_loss: 212.8459\n",
      "Epoch 13/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9520 - loss: 216.5026 - val_accuracy: 0.9521 - val_loss: 211.7836\n",
      "Epoch 14/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9521 - loss: 215.5302 - val_accuracy: 0.9522 - val_loss: 211.1019\n",
      "Epoch 15/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9523 - loss: 215.3535 - val_accuracy: 0.9520 - val_loss: 210.2444\n",
      "Epoch 16/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9522 - loss: 214.5678 - val_accuracy: 0.9521 - val_loss: 211.9790\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 20:22:13.949340: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_8]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9525 - loss: 214.0702 - val_accuracy: 0.9520 - val_loss: 211.2542\n",
      "Epoch 18/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9525 - loss: 213.2520 - val_accuracy: 0.9525 - val_loss: 211.1736\n",
      "Epoch 19/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9525 - loss: 212.9693 - val_accuracy: 0.9526 - val_loss: 211.2120\n",
      "Epoch 20/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9524 - loss: 212.2003 - val_accuracy: 0.9524 - val_loss: 210.9757\n",
      "Model training finished.\n",
      "Evaluating model performance...\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9524 - loss: 214.1785\n",
      "Test accuracy: 95.24%\n"
     ]
    }
   ],
   "source": [
    "# `rankdir='LR'` is to make the graph horizontal.\n",
    "keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, rankdir=\"LR\")\n",
    "\n",
    "\n",
    "# Create an early stopping callback.\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"Start training the model...\")\n",
    "train_dataset = get_dataset_from_csv(\n",
    "    train_data_file, shuffle=True, batch_size=batch_size\n",
    ")\n",
    "valid_dataset = get_dataset_from_csv(valid_data_file, batch_size=batch_size)\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "print(\"Model training finished.\")\n",
    "\n",
    "print(\"Evaluating model performance...\")\n",
    "test_dataset = get_dataset_from_csv(test_data_file, batch_size=batch_size)\n",
    "_, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d164676-dd76-4e6b-b331-214a4dbb903a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3743dc7f-f84c-4d26-86db-c9569d6c303d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da9e23-7640-467a-ab8e-9388976130cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df7454-ceaf-4b8d-871b-278a99222d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67980a-1e67-471a-b5b9-dd2a67856f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11847348-ec8f-48ec-a6ee-287f54a1bf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618d256-51ab-4c2b-8dee-9a9c9bc04b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb55de7-f13c-4d0a-9ed3-cfbd52f22449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e821e-5653-40b1-bc56-ec39819d8fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16916572-dd9b-4e39-abad-1beccf69f877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bb773-9ceb-4c47-a379-8ea8aa8ff1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459768a2-96df-4535-8662-8d2cf1979511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac849df-beb5-4995-80dc-5246ac06850f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d30ea41-1fbf-4a0d-86e4-62b2cef2c7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1576af-8fa7-4184-a266-01af2e0aa9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab8f29-5bc4-4980-9829-9792deb45d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3ef38-5831-4eea-b2b9-4027e3fa96dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
