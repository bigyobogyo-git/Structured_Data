{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8588661d-129f-40f2-9101-129ae42d0ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
    "fname = \"creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c76b43-d2e4-4c64-9669-d53712bc76e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb36576e-ecfe-46d8-8eed-98aa1e194c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e4f9cc-9ec3-4698-888b-cbae6b145a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5f0cfe0-c6be-4cb0-975a-13a1d12526ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 19:12:16.261980: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762452739.241707    9225 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9048 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m7,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,777</span> (546.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,777\u001b[0m (546.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,777</span> (546.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,777\u001b[0m (546.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=train_features.shape[1:]),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2deeec8f-cc4a-4f96-ad5b-a257335c325c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 19:12:26.584486: I external/local_xla/xla/service/service.cc:163] XLA service 0x7d31c800eb50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-06 19:12:26.584497: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2025-11-06 19:12:26.642991: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-06 19:12:26.845935: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91500\n",
      "I0000 00:00:1762452747.882073   11127 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 - 4s - 37ms/step - fn: 45.0000 - fp: 30986.0000 - loss: 2.3999e-06 - precision: 0.0119 - recall: 0.8921 - tn: 196443.0000 - tp: 372.0000 - val_fn: 9.0000 - val_fp: 1820.0000 - val_loss: 0.1400 - val_precision: 0.0350 - val_recall: 0.8800 - val_tn: 55066.0000 - val_tp: 66.0000\n",
      "Epoch 2/30\n",
      "112/112 - 0s - 2ms/step - fn: 36.0000 - fp: 8279.0000 - loss: 1.4943e-06 - precision: 0.0440 - recall: 0.9137 - tn: 219150.0000 - tp: 381.0000 - val_fn: 11.0000 - val_fp: 288.0000 - val_loss: 0.0427 - val_precision: 0.1818 - val_recall: 0.8533 - val_tn: 56598.0000 - val_tp: 64.0000\n",
      "Epoch 3/30\n",
      "112/112 - 0s - 2ms/step - fn: 32.0000 - fp: 6838.0000 - loss: 1.1953e-06 - precision: 0.0533 - recall: 0.9233 - tn: 220591.0000 - tp: 385.0000 - val_fn: 12.0000 - val_fp: 329.0000 - val_loss: 0.0511 - val_precision: 0.1607 - val_recall: 0.8400 - val_tn: 56557.0000 - val_tp: 63.0000\n",
      "Epoch 4/30\n",
      "112/112 - 0s - 2ms/step - fn: 25.0000 - fp: 7688.0000 - loss: 1.0379e-06 - precision: 0.0485 - recall: 0.9400 - tn: 219741.0000 - tp: 392.0000 - val_fn: 7.0000 - val_fp: 2736.0000 - val_loss: 0.1354 - val_precision: 0.0243 - val_recall: 0.9067 - val_tn: 54150.0000 - val_tp: 68.0000\n",
      "Epoch 5/30\n",
      "112/112 - 0s - 2ms/step - fn: 22.0000 - fp: 6683.0000 - loss: 9.2022e-07 - precision: 0.0558 - recall: 0.9472 - tn: 220746.0000 - tp: 395.0000 - val_fn: 10.0000 - val_fp: 425.0000 - val_loss: 0.0289 - val_precision: 0.1327 - val_recall: 0.8667 - val_tn: 56461.0000 - val_tp: 65.0000\n",
      "Epoch 6/30\n",
      "112/112 - 0s - 2ms/step - fn: 21.0000 - fp: 6661.0000 - loss: 7.4992e-07 - precision: 0.0561 - recall: 0.9496 - tn: 220768.0000 - tp: 396.0000 - val_fn: 6.0000 - val_fp: 1920.0000 - val_loss: 0.0801 - val_precision: 0.0347 - val_recall: 0.9200 - val_tn: 54966.0000 - val_tp: 69.0000\n",
      "Epoch 7/30\n",
      "112/112 - 0s - 2ms/step - fn: 17.0000 - fp: 5926.0000 - loss: 6.0696e-07 - precision: 0.0632 - recall: 0.9592 - tn: 221503.0000 - tp: 400.0000 - val_fn: 6.0000 - val_fp: 2398.0000 - val_loss: 0.0945 - val_precision: 0.0280 - val_recall: 0.9200 - val_tn: 54488.0000 - val_tp: 69.0000\n",
      "Epoch 8/30\n",
      "112/112 - 0s - 3ms/step - fn: 14.0000 - fp: 7013.0000 - loss: 7.7688e-07 - precision: 0.0543 - recall: 0.9664 - tn: 220416.0000 - tp: 403.0000 - val_fn: 8.0000 - val_fp: 946.0000 - val_loss: 0.0448 - val_precision: 0.0661 - val_recall: 0.8933 - val_tn: 55940.0000 - val_tp: 67.0000\n",
      "Epoch 9/30\n",
      "112/112 - 0s - 2ms/step - fn: 16.0000 - fp: 6436.0000 - loss: 6.7065e-07 - precision: 0.0587 - recall: 0.9616 - tn: 220993.0000 - tp: 401.0000 - val_fn: 4.0000 - val_fp: 5960.0000 - val_loss: 0.2271 - val_precision: 0.0118 - val_recall: 0.9467 - val_tn: 50926.0000 - val_tp: 71.0000\n",
      "Epoch 10/30\n",
      "112/112 - 0s - 2ms/step - fn: 12.0000 - fp: 7015.0000 - loss: 6.0461e-07 - precision: 0.0546 - recall: 0.9712 - tn: 220414.0000 - tp: 405.0000 - val_fn: 10.0000 - val_fp: 377.0000 - val_loss: 0.0177 - val_precision: 0.1471 - val_recall: 0.8667 - val_tn: 56509.0000 - val_tp: 65.0000\n",
      "Epoch 11/30\n",
      "112/112 - 0s - 2ms/step - fn: 7.0000 - fp: 5838.0000 - loss: 5.0916e-07 - precision: 0.0656 - recall: 0.9832 - tn: 221591.0000 - tp: 410.0000 - val_fn: 9.0000 - val_fp: 1014.0000 - val_loss: 0.0515 - val_precision: 0.0611 - val_recall: 0.8800 - val_tn: 55872.0000 - val_tp: 66.0000\n",
      "Epoch 12/30\n",
      "112/112 - 0s - 2ms/step - fn: 8.0000 - fp: 6303.0000 - loss: 4.8309e-07 - precision: 0.0609 - recall: 0.9808 - tn: 221126.0000 - tp: 409.0000 - val_fn: 8.0000 - val_fp: 639.0000 - val_loss: 0.0260 - val_precision: 0.0949 - val_recall: 0.8933 - val_tn: 56247.0000 - val_tp: 67.0000\n",
      "Epoch 13/30\n",
      "112/112 - 0s - 2ms/step - fn: 9.0000 - fp: 7012.0000 - loss: 6.5870e-07 - precision: 0.0550 - recall: 0.9784 - tn: 220417.0000 - tp: 408.0000 - val_fn: 7.0000 - val_fp: 644.0000 - val_loss: 0.0301 - val_precision: 0.0955 - val_recall: 0.9067 - val_tn: 56242.0000 - val_tp: 68.0000\n",
      "Epoch 14/30\n",
      "112/112 - 0s - 2ms/step - fn: 5.0000 - fp: 5277.0000 - loss: 4.1768e-07 - precision: 0.0724 - recall: 0.9880 - tn: 222152.0000 - tp: 412.0000 - val_fn: 8.0000 - val_fp: 489.0000 - val_loss: 0.0206 - val_precision: 0.1205 - val_recall: 0.8933 - val_tn: 56397.0000 - val_tp: 67.0000\n",
      "Epoch 15/30\n",
      "112/112 - 0s - 2ms/step - fn: 7.0000 - fp: 4683.0000 - loss: 4.7516e-07 - precision: 0.0805 - recall: 0.9832 - tn: 222746.0000 - tp: 410.0000 - val_fn: 7.0000 - val_fp: 1644.0000 - val_loss: 0.0557 - val_precision: 0.0397 - val_recall: 0.9067 - val_tn: 55242.0000 - val_tp: 68.0000\n",
      "Epoch 16/30\n",
      "112/112 - 0s - 2ms/step - fn: 9.0000 - fp: 7041.0000 - loss: 5.8024e-07 - precision: 0.0548 - recall: 0.9784 - tn: 220388.0000 - tp: 408.0000 - val_fn: 6.0000 - val_fp: 3029.0000 - val_loss: 0.1083 - val_precision: 0.0223 - val_recall: 0.9200 - val_tn: 53857.0000 - val_tp: 69.0000\n",
      "Epoch 17/30\n",
      "112/112 - 0s - 2ms/step - fn: 5.0000 - fp: 5592.0000 - loss: 4.6044e-07 - precision: 0.0686 - recall: 0.9880 - tn: 221837.0000 - tp: 412.0000 - val_fn: 7.0000 - val_fp: 1655.0000 - val_loss: 0.0613 - val_precision: 0.0395 - val_recall: 0.9067 - val_tn: 55231.0000 - val_tp: 68.0000\n",
      "Epoch 18/30\n",
      "112/112 - 0s - 2ms/step - fn: 4.0000 - fp: 4449.0000 - loss: 3.7240e-07 - precision: 0.0849 - recall: 0.9904 - tn: 222980.0000 - tp: 413.0000 - val_fn: 10.0000 - val_fp: 1723.0000 - val_loss: 0.0958 - val_precision: 0.0364 - val_recall: 0.8667 - val_tn: 55163.0000 - val_tp: 65.0000\n",
      "Epoch 19/30\n",
      "112/112 - 0s - 2ms/step - fn: 8.0000 - fp: 7164.0000 - loss: 5.8659e-07 - precision: 0.0540 - recall: 0.9808 - tn: 220265.0000 - tp: 409.0000 - val_fn: 8.0000 - val_fp: 803.0000 - val_loss: 0.0623 - val_precision: 0.0770 - val_recall: 0.8933 - val_tn: 56083.0000 - val_tp: 67.0000\n",
      "Epoch 20/30\n",
      "112/112 - 0s - 2ms/step - fn: 6.0000 - fp: 6218.0000 - loss: 5.0416e-07 - precision: 0.0620 - recall: 0.9856 - tn: 221211.0000 - tp: 411.0000 - val_fn: 9.0000 - val_fp: 657.0000 - val_loss: 0.0267 - val_precision: 0.0913 - val_recall: 0.8800 - val_tn: 56229.0000 - val_tp: 66.0000\n",
      "Epoch 21/30\n",
      "112/112 - 0s - 2ms/step - fn: 6.0000 - fp: 6406.0000 - loss: 6.6202e-07 - precision: 0.0603 - recall: 0.9856 - tn: 221023.0000 - tp: 411.0000 - val_fn: 7.0000 - val_fp: 1067.0000 - val_loss: 0.1820 - val_precision: 0.0599 - val_recall: 0.9067 - val_tn: 55819.0000 - val_tp: 68.0000\n",
      "Epoch 22/30\n",
      "112/112 - 0s - 3ms/step - fn: 7.0000 - fp: 5224.0000 - loss: 6.6955e-07 - precision: 0.0728 - recall: 0.9832 - tn: 222205.0000 - tp: 410.0000 - val_fn: 6.0000 - val_fp: 2893.0000 - val_loss: 0.1180 - val_precision: 0.0233 - val_recall: 0.9200 - val_tn: 53993.0000 - val_tp: 69.0000\n",
      "Epoch 23/30\n",
      "112/112 - 0s - 2ms/step - fn: 9.0000 - fp: 7992.0000 - loss: 6.4730e-07 - precision: 0.0486 - recall: 0.9784 - tn: 219437.0000 - tp: 408.0000 - val_fn: 11.0000 - val_fp: 249.0000 - val_loss: 0.0169 - val_precision: 0.2045 - val_recall: 0.8533 - val_tn: 56637.0000 - val_tp: 64.0000\n",
      "Epoch 24/30\n",
      "112/112 - 0s - 2ms/step - fn: 5.0000 - fp: 3271.0000 - loss: 3.3483e-07 - precision: 0.1119 - recall: 0.9880 - tn: 224158.0000 - tp: 412.0000 - val_fn: 9.0000 - val_fp: 594.0000 - val_loss: 0.0331 - val_precision: 0.1000 - val_recall: 0.8800 - val_tn: 56292.0000 - val_tp: 66.0000\n",
      "Epoch 25/30\n",
      "112/112 - 0s - 2ms/step - fn: 5.0000 - fp: 3504.0000 - loss: 3.5273e-07 - precision: 0.1052 - recall: 0.9880 - tn: 223925.0000 - tp: 412.0000 - val_fn: 9.0000 - val_fp: 533.0000 - val_loss: 0.0240 - val_precision: 0.1102 - val_recall: 0.8800 - val_tn: 56353.0000 - val_tp: 66.0000\n",
      "Epoch 26/30\n",
      "112/112 - 0s - 2ms/step - fn: 5.0000 - fp: 3241.0000 - loss: 2.9797e-07 - precision: 0.1128 - recall: 0.9880 - tn: 224188.0000 - tp: 412.0000 - val_fn: 10.0000 - val_fp: 816.0000 - val_loss: 0.0831 - val_precision: 0.0738 - val_recall: 0.8667 - val_tn: 56070.0000 - val_tp: 65.0000\n",
      "Epoch 27/30\n",
      "112/112 - 0s - 2ms/step - fn: 4.0000 - fp: 4376.0000 - loss: 5.4412e-07 - precision: 0.0862 - recall: 0.9904 - tn: 223053.0000 - tp: 413.0000 - val_fn: 9.0000 - val_fp: 1068.0000 - val_loss: 0.0427 - val_precision: 0.0582 - val_recall: 0.8800 - val_tn: 55818.0000 - val_tp: 66.0000\n",
      "Epoch 28/30\n",
      "112/112 - 0s - 2ms/step - fn: 0.0000e+00 - fp: 3308.0000 - loss: 2.3446e-07 - precision: 0.1119 - recall: 1.0000 - tn: 224121.0000 - tp: 417.0000 - val_fn: 10.0000 - val_fp: 231.0000 - val_loss: 0.0123 - val_precision: 0.2196 - val_recall: 0.8667 - val_tn: 56655.0000 - val_tp: 65.0000\n",
      "Epoch 29/30\n",
      "112/112 - 0s - 3ms/step - fn: 2.0000 - fp: 2705.0000 - loss: 2.3710e-07 - precision: 0.1330 - recall: 0.9952 - tn: 224724.0000 - tp: 415.0000 - val_fn: 9.0000 - val_fp: 915.0000 - val_loss: 0.0402 - val_precision: 0.0673 - val_recall: 0.8800 - val_tn: 55971.0000 - val_tp: 66.0000\n",
      "Epoch 30/30\n",
      "112/112 - 0s - 2ms/step - fn: 1.0000 - fp: 2684.0000 - loss: 2.5029e-07 - precision: 0.1342 - recall: 0.9976 - tn: 224745.0000 - tp: 416.0000 - val_fn: 11.0000 - val_fp: 531.0000 - val_loss: 0.0221 - val_precision: 0.1076 - val_recall: 0.8533 - val_tn: 56355.0000 - val_tp: 64.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d32d81107c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.keras\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a7542-a9c1-4bb5-a65b-792d87515dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b221cb-9ef0-4039-b81e-bdc0a49baec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2394be-ac37-4466-a934-668781d7407a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193b311-c9db-4e98-9301-0b9b49046f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58bc93-7a6a-48b9-af78-1464ecfcee23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13c305-273b-4180-b287-3581168efbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e65396-c491-4544-a679-27fa46d7d1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e799b97-50d9-466b-9794-d00335783f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e38607-93a1-486a-993f-c0cc5e91db33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54835e7-d6f8-43b2-b61b-e23dfae836ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66bde48-e820-4432-8168-6e554596ba55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658630e8-0097-456e-8ee3-c917baa235f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6531706-c3bb-4519-b0f4-eec13424526b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0b50e-91d7-4527-92bf-7b881dee4056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17f102-cf18-4dba-b767-2b514b43ba3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172c5e8-b8b5-4b64-a328-5654f870b795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d084de-e1c6-40f2-8843-698b8c7b69e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ec30b-bcfd-436d-8e6c-21126b890120",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
